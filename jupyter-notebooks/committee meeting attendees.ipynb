{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example flow for processing and aggregating stats about committee meeting attendees and protocol parts\n",
    "\n",
    "See the [DataFlows documentation](https://github.com/datahq/dataflows) for more details regarding the Flow object and processing functions.\n",
    "\n",
    "Feel free to modify and commit changes which demonstrate additional functionality or relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from dataflows import Flow, filter_rows, cache, dump_to_path\n",
    "from datapackage_pipelines_knesset.common_flow import load_knesset_data, load_member_names\n",
    "import tabulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit processing of protocol parts for development\n",
    "PROCESS_PARTS_LIMIT = 500\n",
    "\n",
    "# Enable caching of protocol parts data (not efficient, should only be used for local development with sensible PROCESS_PARTS_LIMIT)\n",
    "PROCESS_PARTS_CACHE = True\n",
    "\n",
    "# Filter the meetings to be processed, these kwargs are passed along to DataFlows filter_rows processor for meetings resource\n",
    "MEETINGS_FILTER_ROWS_KWARGS = {'equals': [{'KnessetNum': 20}]}\n",
    "\n",
    "# Don'e use local data - loads everything from knesset data remote storage\n",
    "# When set to False - also enables caching, so you won't download from remote storage on 2nd run.\n",
    "USE_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/members/mk_individual/datapackage.json\n",
      "using cache data from .cache/members-mk-individual-names\n",
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/people/committees/meeting-attendees/datapackage.json\n"
     ]
    }
   ],
   "source": [
    "from dataflows import filter_rows, cache\n",
    "from datapackage_pipelines_knesset.common_flow import load_knesset_data, load_member_names\n",
    "\n",
    "# Loads a dict containing mapping between knesset member id and the member name\n",
    "member_names = load_member_names(use_data=USE_DATA)\n",
    "\n",
    "# define flow steps for loading the source committee meetings data\n",
    "# the actual loading is done later in the Flow\n",
    "load_steps = (\n",
    "    load_knesset_data('people/committees/meeting-attendees/datapackage.json', USE_DATA),\n",
    "    filter_rows(**MEETINGS_FILTER_ROWS_KWARGS)\n",
    ")\n",
    "\n",
    "if not USE_DATA:\n",
    "    # when loading from URL - enable caching which will skip loading on 2nd run\n",
    "    load_steps = (cache(*load_steps, cache_path='.cache/people-committee-meeting-attendees-knesset-20'),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the datapackages which will be loaded\n",
    "\n",
    "Last command's output log should contain urls to datapackage.json files, open them and check the table schema to see the resource metadata and available fields which you can use in the processing functions.\n",
    "\n",
    "Check the [frictionlessdata docs](https://frictionlessdata.io/docs/) for more details about the datapackage file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "stats = defaultdict(int)\n",
    "member_attended_meetings = defaultdict(int)\n",
    "\n",
    "def process_meeting_protocol_part(row):\n",
    "    stats['processed parts'] += 1\n",
    "    if row['body'] and 'אנחנו ככנסת צריכים להיות ערוכים' in row['body']:\n",
    "        stats['meetings contain text: we as knesset need to be prepared'] += 1\n",
    "\n",
    "def process_meeting(row):\n",
    "    stats['total meetings'] += 1\n",
    "    if row['attended_mk_individual_ids']:\n",
    "        for mk_id in row['attended_mk_individual_ids']:\n",
    "            member_attended_meetings[mk_id] += 1\n",
    "    parts_filename = row['parts_parsed_filename']\n",
    "    if parts_filename:\n",
    "        if PROCESS_PARTS_LIMIT and stats['processed parts'] < PROCESS_PARTS_LIMIT:\n",
    "            steps = (load_knesset_data('committees/meeting_protocols_parts/' + parts_filename, USE_DATA),)\n",
    "            if not USE_DATA and PROCESS_PARTS_CACHE:\n",
    "                steps = (cache(*steps, cache_path='.cache/committee-meeting-protocol-parts/' + parts_filename),)\n",
    "            steps += (process_meeting_protocol_part,)\n",
    "            Flow(*steps).process()\n",
    "\n",
    "process_steps = (process_meeting,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cache data from .cache/people-committee-meeting-attendees-knesset-20\n",
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/committees/meeting_protocols_parts/files/5/6/562716.csv\n",
      "using cache data from .cache/committee-meeting-protocol-parts/files/5/6/562716.csv\n",
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/committees/meeting_protocols_parts/files/5/6/563293.csv\n",
      "using cache data from .cache/committee-meeting-protocol-parts/files/5/6/563293.csv\n",
      "loading from url: https://storage.googleapis.com/knesset-data-pipelines/data/committees/meeting_protocols_parts/files/5/6/563590.csv\n",
      "using cache data from .cache/committee-meeting-protocol-parts/files/5/6/563590.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<datapackage.package.Package at 0x7f41d8507d30>,\n",
       " {'count_of_rows': 9402,\n",
       "  'bytes': 27206706,\n",
       "  'hash': '3e74ee573a051cd5dab67aab0e667a29',\n",
       "  'dataset_name': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataflows import Flow, dump_to_path\n",
    "\n",
    "Flow(*load_steps, *process_steps, dump_to_path('data/committee-meeting-attendees-parts')).process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate and print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- top attended members --\n",
      "['איתן ברושי', 'מיכאל לוי', 'דוב חנין', 'משה גפני', 'אורי מקלב']\n",
      "\n",
      "\n",
      "-- stats --\n",
      "processed parts: 624\n",
      "total meetings: 9402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import yaml\n",
    "\n",
    "top_attended_member_names = [member_names[mk_id] for mk_id, num_attended in\n",
    "                             deque(sorted(member_attended_meetings.items(), key=lambda kv: kv[1]), maxlen=5)]\n",
    "print('\\n')\n",
    "print('-- top attended members --')\n",
    "print(top_attended_member_names)\n",
    "print('\\n')\n",
    "print('-- stats --')\n",
    "print(yaml.dump(dict(stats), default_flow_style=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get output data\n",
    "\n",
    "Output data is available in the left sidebar under data directory, you can check the datapackage.json and created csv file to explore the data and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
